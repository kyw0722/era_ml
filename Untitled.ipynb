{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4708a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5fa24719",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_k_fip = pd.read_csv(\"./bb_fip.csv\")\n",
    "FBv = pd.read_csv(\"./FBv.csv\")\n",
    "HR = pd.read_csv(\"./HR.csv\")\n",
    "pull = pd.read_csv(\"./pull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5da363e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_k = bb_k_fip[['BB', 'K']]\n",
    "fip = bb_k_fip[['FIP']]\n",
    "FBv = FBv[['FBv']]\n",
    "HR = HR[['HR']]\n",
    "pull = pull[['Pull']]\n",
    "\n",
    "X_train = pd.concat([bb_k, HR], axis = 1)\n",
    "X_train = pd.concat([X_train, FBv], axis = 1)\n",
    "# X_train = pd.concat([X_train, HR], axis = 1)\n",
    "#X_train = pd.concat([X_train, pull], axis = 1)\n",
    "y_train = fip[['FIP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8360959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2698 entries, 0 to 2697\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   BB      2698 non-null   float64\n",
      " 1   K       2698 non-null   float64\n",
      " 2   HR      2698 non-null   int64  \n",
      " 3   FBv     2698 non-null   float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 84.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9c5c4ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "570e9fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.171679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.752043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               FIP\n",
       "count  2698.000000\n",
       "mean      4.171679\n",
       "std       0.752043\n",
       "min       1.630000\n",
       "25%       3.680000\n",
       "50%       4.170000\n",
       "75%       4.690000\n",
       "max       6.760000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "38d051ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['fip_cut'] = pd.cut(y_train.FIP, bins = [0, 3, 4, 5, 7], labels = [\"elite\", \"average\", \"poor\", \"awful\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ee92498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIP</th>\n",
       "      <th>fip_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.19</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.19</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.11</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.79</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.33</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>4.17</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>3.55</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>3.25</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>3.48</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>2.59</td>\n",
       "      <td>elite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIP  fip_cut\n",
       "0     3.19  average\n",
       "1     3.19  average\n",
       "2     3.11  average\n",
       "3     3.79  average\n",
       "4     4.33     poor\n",
       "...    ...      ...\n",
       "2693  4.17     poor\n",
       "2694  3.55  average\n",
       "2695  3.25  average\n",
       "2696  3.48  average\n",
       "2697  2.59    elite\n",
       "\n",
       "[2698 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c4840831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(y_train[['fip_cut']])\n",
    "\n",
    "y_train_res = ohe.transform(y_train[['fip_cut']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "415d11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe = pd.DataFrame(y_train_res.todense(), columns = ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ebc172a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X_train, y_train_ohe, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f96885da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "464ef6d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 387us/step - loss: 1.2845 - accuracy: 0.3536\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 368us/step - loss: 1.1365 - accuracy: 0.4615\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 1.0852 - accuracy: 0.5528\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 350us/step - loss: 1.0320 - accuracy: 0.6098\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 338us/step - loss: 0.9806 - accuracy: 0.6325\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 337us/step - loss: 0.9340 - accuracy: 0.6395\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 341us/step - loss: 0.8936 - accuracy: 0.6409\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 345us/step - loss: 0.8585 - accuracy: 0.6455\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.8278 - accuracy: 0.6478\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.8013 - accuracy: 0.6474\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 345us/step - loss: 0.7784 - accuracy: 0.6501\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.7561 - accuracy: 0.6599\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 338us/step - loss: 0.7381 - accuracy: 0.6589\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 335us/step - loss: 0.7213 - accuracy: 0.6664\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 341us/step - loss: 0.7076 - accuracy: 0.6733\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.6949 - accuracy: 0.6854\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 336us/step - loss: 0.6851 - accuracy: 0.6886\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 349us/step - loss: 0.6742 - accuracy: 0.6965\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 343us/step - loss: 0.6672 - accuracy: 0.6909\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 341us/step - loss: 0.6576 - accuracy: 0.6965\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 349us/step - loss: 0.6518 - accuracy: 0.7030\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 343us/step - loss: 0.6471 - accuracy: 0.7039\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 348us/step - loss: 0.6417 - accuracy: 0.7057\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 345us/step - loss: 0.6366 - accuracy: 0.7113\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 347us/step - loss: 0.6333 - accuracy: 0.7099\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 337us/step - loss: 0.6275 - accuracy: 0.7108\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 347us/step - loss: 0.6252 - accuracy: 0.7141\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 343us/step - loss: 0.6223 - accuracy: 0.7192\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 356us/step - loss: 0.6189 - accuracy: 0.7159\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 347us/step - loss: 0.6170 - accuracy: 0.7201\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 357us/step - loss: 0.6156 - accuracy: 0.7210\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 363us/step - loss: 0.6141 - accuracy: 0.7159\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 356us/step - loss: 0.6107 - accuracy: 0.7210\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.6095 - accuracy: 0.7220\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 350us/step - loss: 0.6067 - accuracy: 0.7238\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 341us/step - loss: 0.6074 - accuracy: 0.7271\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.6039 - accuracy: 0.7271\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 360us/step - loss: 0.6031 - accuracy: 0.7280\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 369us/step - loss: 0.6013 - accuracy: 0.7261\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 365us/step - loss: 0.6022 - accuracy: 0.7275\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.5996 - accuracy: 0.7303\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 347us/step - loss: 0.5986 - accuracy: 0.7303\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 354us/step - loss: 0.5985 - accuracy: 0.7326\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 339us/step - loss: 0.5978 - accuracy: 0.7252\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 350us/step - loss: 0.5971 - accuracy: 0.7349\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 348us/step - loss: 0.5982 - accuracy: 0.7271\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 350us/step - loss: 0.5946 - accuracy: 0.7298\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.5945 - accuracy: 0.7308\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 368us/step - loss: 0.5936 - accuracy: 0.7354\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 363us/step - loss: 0.5927 - accuracy: 0.7331\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.5950 - accuracy: 0.7294\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 348us/step - loss: 0.5938 - accuracy: 0.7308\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 348us/step - loss: 0.5953 - accuracy: 0.7345\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 349us/step - loss: 0.5920 - accuracy: 0.7303\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 348us/step - loss: 0.5912 - accuracy: 0.7322\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 339us/step - loss: 0.5909 - accuracy: 0.7266\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 368us/step - loss: 0.5902 - accuracy: 0.7335\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 349us/step - loss: 0.5915 - accuracy: 0.7308\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 359us/step - loss: 0.5903 - accuracy: 0.7326\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 347us/step - loss: 0.5907 - accuracy: 0.7322\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 347us/step - loss: 0.5887 - accuracy: 0.7335\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 345us/step - loss: 0.5880 - accuracy: 0.7312\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.5892 - accuracy: 0.7331\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 339us/step - loss: 0.5890 - accuracy: 0.7312\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 339us/step - loss: 0.5882 - accuracy: 0.7363\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.5870 - accuracy: 0.7340\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 339us/step - loss: 0.5870 - accuracy: 0.7335\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.5870 - accuracy: 0.7317\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.5867 - accuracy: 0.7308\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 349us/step - loss: 0.5876 - accuracy: 0.7335\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 341us/step - loss: 0.5868 - accuracy: 0.7359\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.5865 - accuracy: 0.7349\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.5867 - accuracy: 0.7271\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.5862 - accuracy: 0.7331\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 338us/step - loss: 0.5873 - accuracy: 0.7322\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 344us/step - loss: 0.5887 - accuracy: 0.7271\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.5848 - accuracy: 0.7331\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 347us/step - loss: 0.5855 - accuracy: 0.7386\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 339us/step - loss: 0.5852 - accuracy: 0.7354\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 336us/step - loss: 0.5851 - accuracy: 0.7373\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.5852 - accuracy: 0.7363\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 344us/step - loss: 0.5842 - accuracy: 0.7340\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 340us/step - loss: 0.5872 - accuracy: 0.7335\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 341us/step - loss: 0.5868 - accuracy: 0.7275\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 360us/step - loss: 0.5845 - accuracy: 0.7400\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 342us/step - loss: 0.5858 - accuracy: 0.7303\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 337us/step - loss: 0.5842 - accuracy: 0.7368\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 338us/step - loss: 0.5841 - accuracy: 0.7326\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 332us/step - loss: 0.5841 - accuracy: 0.7340\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 338us/step - loss: 0.5846 - accuracy: 0.7340\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 332us/step - loss: 0.5846 - accuracy: 0.7349\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 331us/step - loss: 0.5850 - accuracy: 0.7312\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 332us/step - loss: 0.5851 - accuracy: 0.7354\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 335us/step - loss: 0.5866 - accuracy: 0.7322\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 334us/step - loss: 0.5829 - accuracy: 0.7373\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 334us/step - loss: 0.5843 - accuracy: 0.7275\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 335us/step - loss: 0.5842 - accuracy: 0.7312\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 331us/step - loss: 0.5843 - accuracy: 0.7326\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 337us/step - loss: 0.5832 - accuracy: 0.7349\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 341us/step - loss: 0.5832 - accuracy: 0.7340\n",
      "17/17 [==============================] - 0s 306us/step\n"
     ]
    }
   ],
   "source": [
    "modelDNN = Sequential()\n",
    "modelDNN.add(Dense(64, activation=\"relu\", input_dim = 4))\n",
    "modelDNN.add(Dense(4, activation=\"softmax\"))\n",
    "modelDNN.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "modelDNN.fit(X_tr, y_tr, epochs = 100)\n",
    "\n",
    "pred = modelDNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "203b047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fip_cut_average</th>\n",
       "      <th>fip_cut_awful</th>\n",
       "      <th>fip_cut_elite</th>\n",
       "      <th>fip_cut_poor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fip_cut_average  fip_cut_awful  fip_cut_elite  fip_cut_poor\n",
       "0                 1.0            0.0            0.0           0.0\n",
       "1                 1.0            0.0            0.0           0.0\n",
       "2                 1.0            0.0            0.0           0.0\n",
       "3                 1.0            0.0            0.0           0.0\n",
       "4                 0.0            0.0            0.0           1.0\n",
       "...               ...            ...            ...           ...\n",
       "2693              0.0            0.0            0.0           1.0\n",
       "2694              1.0            0.0            0.0           0.0\n",
       "2695              1.0            0.0            0.0           0.0\n",
       "2696              1.0            0.0            0.0           0.0\n",
       "2697              0.0            0.0            1.0           0.0\n",
       "\n",
       "[2698 rows x 4 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2bcb4070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 3 0 0 3 1 3 1 3 0 3 0 3 3 0 0 3 3 3 0 0 3 3 0 2 0 0 3 0 3 0 0 0 3 0 0\n",
      " 3 0 1 3 0 3 3 3 3 0 0 0 0 0 3 0 3 3 2 3 3 3 3 0 3 3 3 0 3 3 3 3 1 3 3 0 3\n",
      " 0 3 3 0 1 0 3 3 3 0 3 3 0 0 0 3 3 3 3 3 3 3 0 3 2 3 0 3 3 3 3 3 3 2 3 3 1\n",
      " 0 3 3 0 3 0 3 0 3 2 3 0 3 3 3 3 3 3 0 0 0 3 3 0 2 0 1 3 0 3 0 3 3 0 0 3 3\n",
      " 0 3 3 3 3 2 0 1 3 3 3 0 3 0 3 0 1 0 3 3 3 3 2 3 0 3 3 0 0 3 3 0 3 3 3 1 0\n",
      " 3 3 0 3 3 0 3 0 0 3 3 3 3 3 2 1 3 0 2 1 0 2 3 1 3 2 3 0 0 3 3 3 0 0 1 3 3\n",
      " 3 3 0 3 3 3 3 3 3 2 1 0 2 0 3 3 3 3 2 0 3 1 3 0 3 3 0 1 0 3 3 2 0 0 0 3 0\n",
      " 0 3 3 0 3 3 0 3 3 0 3 3 0 0 1 3 0 3 3 0 3 1 3 3 3 3 0 3 3 0 3 0 2 1 3 3 0\n",
      " 3 2 2 0 3 3 0 3 0 2 0 3 1 1 0 3 3 0 3 0 3 0 0 2 1 0 3 3 3 0 0 2 0 3 3 0 0\n",
      " 3 0 0 0 0 3 0 0 3 3 3 3 0 3 3 3 3 3 3 3 3 1 3 0 3 3 3 0 0 3 0 3 0 0 3 0 2\n",
      " 3 0 3 3 3 3 1 0 2 0 0 3 0 2 0 3 3 3 3 1 3 3 0 3 2 3 0 0 3 3 3 3 3 2 3 2 3\n",
      " 2 3 3 3 3 3 3 3 3 3 0 3 3 0 1 0 0 3 0 0 3 1 3 0 0 0 3 0 3 0 0 0 3 3 0 3 3\n",
      " 0 2 0 3 3 0 3 0 3 0 3 0 3 2 3 3 3 0 1 3 3 2 0 3 3 3 3 0 3 0 3 3 0 0 0 0 3\n",
      " 1 1 3 0 0 0 0 3 3 3 1 3 3 0 1 3 1 3 3 0 3 3 0 0 3 3 1 3 0 3 3 3 3 3 3 0 3\n",
      " 0 3 3 0 0 3 1 0 3 0 3 0 3 3 3 3 3 3 3 0 0 3]\n"
     ]
    }
   ],
   "source": [
    "print(pred.argmax(axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d5ab119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(pred.argmax(axis = -1) == 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "446e055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier()\n",
    "modelRF.fit(X_tr, y_tr)\n",
    "\n",
    "predRF = modelRF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "00d25d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6173054251110597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scoreRF = f1_score(y_test, predRF, average = 'macro')\n",
    "print(scoreRF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
